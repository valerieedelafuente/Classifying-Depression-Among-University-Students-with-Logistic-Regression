---
title: "Classifying Depression Among University Students with Logistic Regression"
subtitle: "PSTAT 100: Data Science Concepts and Analysis"
format: 
  pdf: 
    latex-engine: xelatex
    geometry: "letterpaper, margin=0.3in"
    code-fold: true
    code-line-numbers: true
    code-copy: true
    code-tools: true
    self-contained: true
    toc: false
    toc-location: left
    number-sections: true
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  fig.align = 'center'
)

bfcolor <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{\\textbf{%s}}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'><b>%s</b></span>", color, x)
  } else x
}
```

:::: callout
::: {style="text-align: center"}
[**Group Members**]{style="color: blue;"}
:::

-   Valerie De La Fuente (valeriedelafuente)
-   Matthew Arteaga (matthewarteaga)
-   Phuc Lu (pdlu)
-   William Nelson (williamnelson)
-   Hayden Galletta (haydengalletta)
::::

```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE
)
```

```{r, include=FALSE, message=FALSE}
# Load necessary packages
library(readr)
library(tidyverse)
library(naniar)
library(janitor)
library(knitr)
library(rmarkdown)
library(car)
library(caret)
library(readr)
library(knitr)
library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
library(broom)

#setwd("/Documents/PSTAT 100/finalproject/PSTAT-100-Project/")

# Load in the data
depression_data <- read.csv("student_depression_dataset.csv")
```

```{r, include=FALSE}
# Data cleaning and preprocessing

# Fix column names
depression_data <- depression_data %>% 
  clean_names() %>%
  rename(
    cum_gpa = cgpa,
    suicidal_thoughts = have_you_ever_had_suicidal_thoughts,
    fam_mental_illness = family_history_of_mental_illness
  )

# Fixing the `financial_stress` variable
depression_data <- depression_data %>%
  mutate(
    financial_stress = as.numeric(financial_stress), 
    # convert string numbers to integers
    financial_stress = case_when(
      financial_stress == "?" ~ NA,
      # convert "?" to NA values
      .default = financial_stress))

# Remove 3 rows with NA values
depression_data <- depression_data %>% na.omit()

# Factorizing the `gender` variable
depression_data$gender <- factor(depression_data$gender)

# Fixing the `city` variable to change invalid entries
depression_data <- depression_data %>%
  mutate(city = case_when(
    city == "Khaziabad" ~ "Ghaziabad",
    city == "Nalyan" ~ "Kalyan",
    city == "'Less Delhi'" ~ "Delhi",
    city == "'Less than 5 Kalyan'" ~ "Kalyan",
    city == "3.0" ~ "Other",
    city == "Saanvi" ~ "Other",
    city == "M.Tech" ~ "Other",
    city == "Bhavna" ~ "Other",
    city == "City" ~ "Other",
    city == "Mira" ~ "Other",
    city == "Harsha" ~ "Other",
    city == "Vaanya" ~ "Other",
    city == "Gaurav" ~ "Other",
    city == "Harsh" ~ "Other",
    city == "Reyansh" ~ "Other",
    city == "Kibara" ~ "Other",
    city == "Rashi" ~ "Other",
    city == "ME" ~ "Other",
    city == "M.Com" ~ "Other",
    city == "Mihir" ~ "Other",
    city == "Nalini" ~ "Other",
    city == "Nandini" ~ "Other",
    TRUE ~ city  # Leave valid entries as they are
  ))

# # Fixing the `profession` variable to change invalid entries
depression_data <- depression_data %>%
  mutate(profession = case_when(
    profession == "'Civil Engineer'" ~ "Civil Engineer",
    profession == "'UX/UI Designer'" ~ "UX/UI Designer",
    profession == "'Digital Marketer'" ~ "Digital Marketer",
    profession == "'Content Writer'" ~ "Content Writer",
    profession == "'Educational Consultant'" ~ "Educational Consultant",
    TRUE ~ profession # Leave valid entries as they are
  ))


# Fixing the `work_pressure` variable for proper scaling
depression_data <- depression_data %>%
  mutate(work_pressure = case_when(
    work_pressure == 0 ~ 0,
    work_pressure == 2 ~ 1,
    work_pressure == 5 ~ 3
  ))

# Fixing the `sleep_duration` variable to change invalid entries
depression_data <- depression_data %>% 
  mutate(sleep_duration = case_when(
    sleep_duration == "'5-6 hours'" ~ "5-6 hours",
    sleep_duration == "'Less than 5 hours'" ~ "Less than 5 hours",
    sleep_duration == "'7-8 hours'" ~ "7-8 hours",
    sleep_duration == "'More than 8 hours'" ~ "More than 8 hours",
    sleep_duration == "Others" ~ "Other"
  ))

# Factorizing the `sleep_duration` variable
depression_data <- depression_data %>%
  mutate(sleep_duration = factor(sleep_duration, 
                                 levels = c("Less than 5 hours", 
                                            "5-6 hours", 
                                            "7-8 hours", 
                                            "More than 8 hours", 
                                            "Other"),
                                 ordered = TRUE))

# Fixing the `dietary_habits` variable to change misspelling
depression_data <- depression_data %>% 
  mutate(dietary_habits = case_when(
    dietary_habits == "Others" ~ "Other",
    TRUE ~ dietary_habits
  ))

# Factorizing the `dietary_habits` variable
depression_data <- depression_data %>%
  mutate(dietary_habits = factor(dietary_habits,
                                 levels = c("Healthy", "Moderate", "Unhealthy",
                                            "Other"),
                                 ordered = TRUE))

# Fixing the `degree` variable to change invalid entries
depression_data <- depression_data %>%
  mutate(degree = case_when(
    degree == "'Class 12'" ~ "High School",
    degree == "Others" ~ "Other",  
    # Others could less than HS education or totally unknown. 
    .default = degree
  ))

# Factorizing the `degree variable`
degree_levels <- c(
  "High School",
  "BA", "BSc", "B.Com", "BCA", "B.Pharm", "B.Ed", "B.Tech", "BE", "BHM", "B.Arch", "BBA",
  "MA", "MSc", "MBA", "M.Com", "MCA", "M.Tech", "M.Ed", "M.Pharm", "MHM",
  "LLB", "LLM", "MD", "MBBS",
  "PhD",
  "Other"
)

depression_data <- depression_data %>%
  mutate(degree = factor(degree, levels = degree_levels, ordered = TRUE))

# Factorizing the `suicidal_thoughts` variable
depression_data$suicidal_thoughts <- factor(depression_data$suicidal_thoughts)

# Factorizing the `fam_mental_illness` variable
depression_data$fam_mental_illness <- factor(depression_data$fam_mental_illness)

# Turning the `depression` variable back to "yes" and "no" for visualization purposes
depression_data <- depression_data %>% 
  mutate(depression = case_when(
    depression == 0 ~ "No",
    depression == 1 ~ "Yes"
  ))

# Factorizing the `depression` variable
depression_data$depression <- factor(depression_data$depression)
```

```{r}
library(readr)
library(knitr)
library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
library(broom)

depression <- read_csv("student_depression_dataset.csv")

depression <- depression %>% filter(`Sleep Duration` != "Others")

depression$`Sleep Duration` <- as.numeric(factor(
  depression$`Sleep Duration`, levels = c("'Less than 5 hours'", "'5-6 hours'", "'7-8 hours'",
                                          "'More than 8 hours'")))
```

## Abstract

## Introduction

For this project, the Student Depression Dataset by Israel Campero Jurado was used for analysis. This data set was published to OpenML on March 12, 2025 and was retrieved on April 22, 2025. [Link](https://www.openml.org/search?type=data&status=active&id=46753&sort=runs)

This data contains anonymized information that is useful for studying depression levels among students. This data set contains features such as the students’ information (age and gender), their academic performance (grades, and attendance), their lifestyles (sleep patterns, exercise, and social activities), mental health history, and how they would rate their depression on a standardized scale. The raw data file is in the CSV format. The data in this data are structured, where each row represents an individual student and the columns represent a specific variable. 

Previously, those who studied this data set tended to be psychology researchers, data science, and educators. Their aims were to identify factors that contribute to student depression and to design early intervention strategies. This research is also interested in looking at student depression and potential contributing factors. Hence, for this project, we’re interested in answering the following questions:

1. Do certain dietary habits coincide with an increased rate of depression among students?
2. Is there a correlation between the amount of sleep a student gets and the proportion of them that are depressed?
3. Does the presence (and magnitude) of certain stressors have an impact on the rate at which students are depressed?

We propose the following hypotheses:

1. Students with moderate to healthy dietary habits will have lower rates of depression compared to students with unhealthy dietary habits.
2. Students who average more sleep per night will have lower rates of depression compared to students who average less.
3. Students with the highest collective reported stressors (academic pressure, work pressure and financial stress) will have higher rates of depression compared to students with lower collective reported stressors.

## Exploratory Data Analysis

This first graph is a bar plot that helps us visualize hypothesis 1 by visualizing the correlation between a healthy diet and depression. Notably, around 45% of students with healthy dietary habits have depression, around 55% of students with moderate dietary habits have depression, and 75% of students with unhealthy dietary habits have depression. The results of this bar plot indicate that depression rates increase and student dietary habits worsen.

```{r}
# For dietary habits
ggplot(depression_data, aes(x = dietary_habits, fill = factor(depression))) +
  geom_bar(position = "fill", color = "black") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Depression Distribution by Dietary Habit",
       x = "Dietary Habit", y = "Proportion",
       fill = "Depression") +
  theme_bw(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The second graph is a bar plot that helps to answer hypothesis 2 by visualizing the correlation between sleep patterns and depression. The results of this bar plot seem to indicate that people getting less than 5 hours of sleep have a significantly higher rate of depression and people who get more than 8 hours of sleep have a significantly lower rate of depression. This indicates that lower rates of depression are linked to a greater daily sleep duration.

```{r}
# Convert 'depression' factor to numeric: "No" = 0, "Yes" = 1
depression_data <- depression_data %>%
  mutate(depression_numeric = as.numeric(depression) - 1)

# Create summarized depression rates and standard errors by sleep duration
sleep_summary <- depression_data %>%
  group_by(sleep_duration) %>%
  summarise(
    mean_dep = mean(depression_numeric, na.rm = TRUE),
    se = sd(depression_numeric, na.rm = TRUE) / sqrt(n())
  )

# Bar plot with error bars
ggplot(sleep_summary, aes(x = sleep_duration, y = mean_dep, fill = sleep_duration)) +
  geom_col(show.legend = FALSE) +

  labs(
    title = "Depression Rate by Sleep Duration",
    x = "Sleep Duration",
    y = "Mean Depression Rate"
  ) +
  theme_minimal(base_size = 13) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

This final graph is a boxplot that helps visualize hypothesis 3 and shows the correlation between multiple stressor factors and depression. The results seem to indicate a correlation with the increased stress levels and depression.

```{r}
depression_data$financial_stress <- as.numeric(depression_data$financial_stress)
depression_data$total_stress <- depression_data$academic_pressure +
                                 depression_data$work_pressure +
                                 depression_data$financial_stress

ggplot(depression_data, aes(x = factor(depression), y = total_stress, fill = factor(depression))) +
  geom_boxplot() +
  labs(
    title = "Total Reported Stress vs Depression",
    x = "Depression (0 = No, 1 = Yes)",
    y = "Total Stress"
  ) +
  scale_fill_discrete(name = "Depression") +
  theme_minimal()
```

## Data Processing

There are 27901 observations and 18 variables in this dataset. The column names in the original dataset were changed to the following: `id`, `gender`, `age`, `city`, `profession`, `academic_pressure`, `work_pressure`, `cum_gpa`, `study_satisfaction`, `job_satisfaction`, `sleep_duration`, `dietary_habits`, `degree`, `suicidal_thoughts`, `work_study_hours`, `financial_stress`, `fam_mental_illness`, and `depression`.

The following variables were mutated:

-   `financial_stress`: variable type was converted to numeric and invalid entries were properly handled.

-   `gender`: variable type was converted to a factor.

-   `city`: typos and invalid entries properly handled.

-   `profession`: invalid entries were properly handled.

-   `sleep_duration`: invalid entries were properly handled and observations in the "Other" category were removed.

-   `dietary_habits`: typos were properly handled.

-   `suicidal_thoughts`: variable type was converted to a factor.

-   `fam_mental_illness`: variable type was converted to a factor.

-   `depression`: variable type was converted to a factor.

There are 3 missing observations present in the dataset, coming from the `financial_stress` variable. This accounts for less than 0.1% of the dataset, so we can easily remove them. With the data processed and tidied, we can move onto modeling.

## Modeling Process

With 3 hypotheses to test, the modeling process will be outlined and broken into 3 parts.

### Hypothesis 1: Students with moderate to healthy dietary habits will have lower rates of depression compared to students with unhealthy dietary habits.

Our first hypothesis we want to test is that students with moderate to healthy dietary habits will have lower rates of depression than students with unhealthy dietary habits. We will fit a basic logistic regression model to predict the binary outcome variable, `depression`, using our categorical variable `dietary_habits` as a predictor.

Before fitting our model, we should first fully understand the predictor we are working with as well as check some assumptions that need to be met for our model to function properly. Our predictor `dietary_habits` is distributed as follows:

```{r, echo=FALSE}
kable(table(depression_data$dietary_habits), col.names = c("Habits", "Count"))
```

We have a slightly skewed distribution of responses between "healthy", "moderate", and "unhealthy" dietary habits, as well as 12 observations that responded "other". Because these 12 responses are a very small fraction of the overall data, we can remove these to simplify our model and our interpretations of it.

```{r, echo=FALSE}
depression_data <- depression_data %>% filter(
  dietary_habits != "Other"
)
```

Logistic regression models rely on several key assumptions to perform correctly. Most of these assumptions have already been met or are reasonably assumed to be satisfied, except for the assumption that the predictor variable should have a linear relationship with the log-odds of the outcome variable. To assess this, we can plot the log-odds of the outcome against the levels of the predictor to evaluate whether the linearity assumption holds.

```{r, echo=FALSE}
depression_data$dietary_habits <- 
  as.numeric(factor(depression_data$dietary_habits, 
                    levels = c("Healthy", "Moderate", "Unhealthy")))

depression_data <- depression_data %>% mutate(
  depression = case_when(
    depression == "Yes" ~ 1,
    depression == "No" ~ 0
  )
)
```

```{r, echo=FALSE, message=FALSE}
logOddsDF <- depression_data %>%
  group_by(dietary_habits) %>%
  summarize(
    odds = mean(depression),
    logOdds = log(odds/(1-odds)))

ggplot(logOddsDF, aes(x = dietary_habits, y = logOdds)) +
  geom_point() + geom_smooth(method = 'lm', se = FALSE) +
  scale_x_continuous(
    breaks = c(1, 2, 3),
    labels = c("Healthy", "Moderate", "Unhealthy")) +  
  labs(title = "Log-Odds of Depression by Dietary Habits", y = "Log-Odds", x = "Dietary Habits") +
  theme_minimal()
```

There appears to be a strong linear relationship between the log-odds of depression by each level of `dietary_habits`, so we can conclude that our data meets the necessary assumption and move on to fitting our model.

### Hypothesis 2: Students who average more sleep per night will have lower rates of depression compared to students who average less.

Based on the hypothesis and the characteristics of the data set, our analytical approach of choice for investigation is classification; where we will construct a logistic regression model in an attempt to predict whether or not a student reports experiencing depression based on how many hours of sleep they average per night. This is the best method of choice because our outcome variable, whether or not the student is depressed, is a binary value and our predictor, the amount of sleep averaged per night, is categorical with an ordinal nature. Additionally, the method quantifies associations and predicts probabilities, and can be extended to control for other factors.

**Assumptions Required for Logistic Regression**: In order to use logistic regression to investigate our hypothesis, there are a few assumptions of the data that must be met in order for the model to be valid. That is (1), the outcome variable is binary (condition is met), (2), that the observations are independent of one another (condition is assumed based on how data was collected), (3), that the log-odds of the outcome is a linear function of the predictor variable, (4), that there is no multicollinearity (not of concern; only one variable involved in model), and (5), that there at least 10 events per predictor level (condition is met). In our case the only assumption that needs to be checked is the linearity of the log-odds.

```{r, fig.align='center'}
bin_summary <- depression %>%
  group_by(`Sleep Duration`) %>%
  summarize(
    mean_depression = mean(Depression),
    n = n(),
    log_odds = log(mean_depression/(1-mean_depression))
  ) %>%
  filter(!is.infinite(log_odds))

ggplot(bin_summary, aes(x = `Sleep Duration`, y = log_odds)) +
  geom_point() + geom_smooth(method = "lm", se = FALSE) +
  scale_x_continuous(
    breaks = c(1, 2, 3, 4),
    labels = c("<5 hrs", "5-6 hrs", "7-8 hrs", ">8 hrs")
  ) +
  labs(title = "Log-Odds vs. Sleep Duration", y = "Log-Odds", x = "Sleep Duration") +
  theme_minimal()

depression <- depression %>% mutate(sleep_log = `Sleep Duration` * log(`Sleep Duration`))
model_bt <- glm(Depression~`Sleep Duration` + sleep_log, family=binomial,data=depression)
model_coef <- as.data.frame(summary(model_bt)$coefficients)
model_coef <- model_coef %>% select(-c(Estimate,`Std. Error`))
```

The graph of log-odds vs. sleep duration shows us a somewhat clear linear relationship between sleep duration and the log-odds. To investigate further, we will use a Box-Tidwell Test and look at the p-value corresponding to `sleep_log` (the log of the `sleep_duration` variable)

```{r}
kable(model_coef, digits = 3, caption="GLM Coefficient Estimates")
```

Based on the p-value of 0.948 corresponding to the `sleep_log` variable, at significance level $\alpha=0.05$, we fail to reject the null hypothesis that the log odds is a linear function of the `sleep_duration` predictor variable, thus the (3) assumption is met and we can proceed to constructing our model.

We will use the `glm` function to generate the following logistic regression model for predicting the proportion of students reporting depression at the varying sleep ranges (and how that may be extrapolated to see how depression rates scale with sleep duration):

$$
\hat{DepressionProportion}=0.72583-0.15739SleepDuration
$$

### Hypothesis 3: Students with the highest collective reported stressors (academic pressure, work pressure and financial stress) will have higher rates of depression compared to students with lower collective reported stressors.

Our final hypothesis we want to test is that students with multiple combined stressors will have a higher overall rate of depression than students without these stressors. We will fit a logistic regression model to predict the binary outcome variable, `depression`, using the numeric variable `total_stress` (combination of `academic_pressure` + `work_pressure` + `financial_stress`) as a predictor.

Before fitting our model, we should first fully understand the predictor we are working with as well as check some assumptions that need to be met for our model to function properly. Our predictor `total_stress` is distributed as follows:

```{r, echo=FALSE}

# Ensure depression is binary numeric
depression_data <- depression_data %>%
  mutate(
    depression_numeric = as.numeric(depression),  # "No" = 0, "Yes" = 1
    financial_stress = as.numeric(financial_stress),  # convert if it's currently character
    total_stress = academic_pressure + work_pressure + financial_stress  # combined stressor score
  )

ggplot(depression_data, aes(x = total_stress)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  labs(title = "Distribution of Total Stress", x = "Total Stress", y = "Count") +
  theme_minimal()
```
Looking at our data we can tell that it has a bell curve distribution and overall has a good representation of many different `total_stress` values. As a result the data does not need any cleaning and is ready to be used in our logistic regression model.

As mentioned in the previous hypothesis, logistic regression models have a few assumptions that we assume to have already met. The only one that we need to verify is the one that says the predictor variable should be linear in the log-odds of the outcome variable. We can check this by plotting the log-odds against the different amounts of `total_stress`:

```{r, echo=FALSE, message=FALSE}

# Fit logistic regression model
logit_model <- glm(depression_numeric ~ total_stress, 
                   data = depression_data, 
                   family = binomial)

# Get predicted log-odds (logits)
depression_data$logit <- predict(logit_model, type = "link")  # link = log-odds

# Plot logit vs total_stress
ggplot(depression_data, aes(x = total_stress, y = logit)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = "loess", color = "blue") +
  labs(
    title = "Linearity in the Logit for Total Stress",
    x = "Total Stress",
    y = "Logit (Log-Odds of Depression)"
  ) +
  theme_minimal()


```

There appears to be a strong linear relationship between the log-odds of `depression` by `total_stress`, so we can conclude that our data meets the necessary assumption and move on to fitting our model.

## Results and Interpretation

### Hypothesis 1: Students with moderate to healthy dietary habits will have lower rates of depression compared to students with unhealthy dietary habits.

We fit a logistic regression model with the logit link function that will predict the odds of having depression by each level of `dietary_habits`. The results of the model are summarized in the following table:

```{r, echo=FALSE}
dietHabitsModel <- glm(depression ~ dietary_habits - 1, data = depression_data,
                       family = binomial(link = 'logit'))

logModelSum <- summary(dietHabitsModel)
kable(logModelSum$coefficients, format = 'markdown', digits = 42)
```

We see statistically significant results from our basic logistic regression model with just dietary habits as a predictor. Every level of dietary habits has statistically significant effects on the presence of depression. Our model predicts that "healthy" dietary habits decrease the probability of depression by about 18.5%, while "moderate" and "unhealthy" dietary habits increase the probability of depression by about 24% and 88% respectively. This is a very strong result to start with, but we should check our model results in other ways as well.

We will first check to make sure the `dietary_habits` categorical predictor is significant in predicting the presence of depression overall rather than just by the level of the variable. We will use the `anova()` function to perform a chi-squared likelihood ratio test with a null hypothesis that the null model without `dietary_habits` is sufficient in predicting depression, and an alternative hypothesis that `dietary_habits` is significant to the model in terms of lowering the model's residual deviance. The results of the ANOVA are the following:

```{r, echo=FALSE}
logModANOVA <- anova(dietHabitsModel)
kable(logModANOVA, digits = 1000)
```

This table shows us that when added to the null model, the `dietary_habits` predictor reduced the model's residual deviance so greatly that the p-value for our likelihood ratio test is too small for R to display it. The true p-value is less than 2.2 \* 10\^-16, which is extremely tiny and reasonably rounded to 0. With this similarly significant result to the model results earlier, we can conclude that the Dietary Habits predictor as a whole is significant in predicting the presence of depression.

We can now check how accurate our model is at predicting the presence of depression using a confusion matrix. The confusion matrix will visualize the accuracy of our model in terms of true positive and negative rates in the diagonal cells, false positive rate in the bottom left cell (row 2, column 1), and false negative rate in the top right cell (row 1, col 2).

```{r, echo=FALSE}
pred_probs <- predict(dietHabitsModel, type = "response")

pred_class <- ifelse(pred_probs > 0.5, 1, 0)

pred_class <- factor(pred_class, levels = c(0, 1))
actual <- factor(depression_data$depression, levels = c(0, 1))

confMat <- confusionMatrix(pred_class, actual, positive = "1")

accuracy <- confMat$overall[1]

kable(confMat$table/(dim(depression_data)[1]), digits = 3)
```

Here we see our model has an accuracy of 61%, a false positive rate of 26.5%, and a false negative rate of 12.5%. This means our model with just `dietary_habits` as a predictor is slightly better at predicting the presence of depression than a random guess.

Despite the fact that this model cannot predict the presence of depression with an impressive accuracy, the results of our model fit and surrounding hypothesis tests lead us to fail to reject our hypothesis that students with moderate to healthy dietary habits will have lower rates of depression than students with unhealthy dietary habits.

### Hypothesis 2: Students who average more sleep per night will have lower rates of depression compared to students who average less.

```{r}
model <- glm(Depression ~ `Sleep Duration`, data = depression, family = binomial)
tidy_model <- tidy(model)
tidy_model <- tidy_model %>%
  mutate(p.value = formatC(p.value, format = "e", digits = 2))
kable(tidy_model,digits=3,caption="Logistic Model Table")
```

```{r, fig.align='center'}

depression$predicted_prob <- predict(model, type = "response")
ggplot(depression, aes(x = `Sleep Duration`, y = predicted_prob)) +
  stat_summary(fun = mean, geom = "point", color = "blue", size = 3) +
  stat_summary(fun = mean, geom = "line", group = 1, color = "blue") +
  labs(title = "Predicted Probability of Depression vs. Sleep Duration",
       y = "Predicted Probability", x = "Sleep Duration") +
  theme_minimal() +
  scale_x_continuous(
    breaks = c(1, 2, 3, 4),
    labels = c("<5 hrs", "5-6 hrs", "7-8 hrs", ">8 hrs")
  )
```

The model has an intercept coefficient of 0.72583, representing the average depression rate for students falling under the `0` Sleep Range (irrelevant as `1` is the reference group; representing less than 5 hours of sleep), and a `sleep_duration` coefficient of -0.15739, representing the average change in depression probability when going from one sleep range to the next (in order). The p-values for both coefficients are \<0.05, indicating statistical significance of the model.

To analyze the performance of the model we will investigate the ROC curve and area under the curve generated by the model:

```{r, fig.align='center'}
library(pROC)
predicted_probs <- predict(model, type = "response")
roc_obj <- roc(depression$Depression, predicted_probs)

plot(roc_obj, main = "ROC Curve", col = "blue")
```

The ROC curve generated by the model is slightly above the diagonal (increasing and concave down), but not by much. Additionally, the AUC generated from the graph is 0.5494. This means that the prediction made by the model is relatively random, skewing slightly towards being a good model (correctly predicting the depression proportion based on `sleep_duration`).

### Hypothesis 3: Students with the highest collective reported stressors (academic pressure, work pressure and financial stress) will have higher rates of depression compared to students with lower collective reported stressors.

We fit a logistic regression model that will predict the odds of having depression by each level of `total_stress`. The results of the model are summarized in the following table:

```{r, echo=FALSE}


model_summary <- summary(logit_model)
coefs <- coef(model_summary)

# Create a data frame manually
logit_df <- data.frame(
  Term = rownames(coefs),
  Estimate = round(coefs[, "Estimate"], 3),
  `Std. Error` = round(coefs[, "Std. Error"], 3),
  `z value` = round(coefs[, "z value"], 2),
  `Pr(>|z|)` = formatC(coefs[, "Pr(>|z|)"], format = "e", digits = 2),
  `Odds Ratio` = round(exp(coefs[, "Estimate"]), 3)
)

# Display nicely with kable
kable(logit_df, caption = "Logistic Regression: Predicting Depression from Total Stress")
```

We see statistically significant results from our basic logistic regression model using `total_stress` as a predictor. Our model predicts that for every one point increase in the presence of `total_stress` will double the likelihood of depression. This is a very strong result to start with, but we should check our model results in other ways as well.

We will first check to make sure the `total_stress` numeric predictor is significant in predicting the presence of depression overall. We will use the `anova()` to perform a chi-squared likelihood ratio test with a null hypothesis that the null model without `total_stress` is sufficient in predicting depression, and an alternative hypothesis that `total_stress` is significant to the model in terms of lowering the model's residual deviance. The results of the ANOVA are the following:

```{r, echo=FALSE}
# Fit null and full models
null_model <- glm(depression ~ 1, data = depression_data, family = binomial)
full_model <- glm(depression ~ total_stress, data = depression_data, family = binomial)

# Likelihood Ratio Test via ANOVA
anova_result <- anova(null_model, full_model, test = "Chisq")

# Convert to data frame and add row names
anova_df <- as.data.frame(anova_result)
anova_df$Model <- rownames(anova_result)

# Reorder columns 
anova_df <- anova_df[, c("Model", "Df", "Deviance", "Resid. Df", "Resid. Dev", "Pr(>Chi)")]

# Rename for clarity
colnames(anova_df) <- c("Model", "Df", "Deviance", "Residual_Df", "Residual_Dev", "P_value")

# Format using kable with scientific notation
knitr::kable(
  anova_df, 
  digits = 4, 
  format.args = list(scientific = TRUE), 
  caption = "Chi-Squared Likelihood Ratio Test: Comparing Null vs. Total Stressors Model"
)
```

This table shows us that when added to the null model, the `total_stress` predictor reduced the model's residual deviance so greatly that the p-value for our likelihood ratio test is too small for R to display it. The true p-value is less than 2.2e-16, which is extremely tiny and reasonably rounded to 0. With this similarly significant result to the model results earlier, we can conclude that the `total_stress` predictor as a whole is significant in predicting the presence of depression. Thus we reject the null hypothesis that the simpler model without `total_stress` is sufficient in predicting depression. The extremely low p-value indicates that the model including `total_stress` provides a significantly better fit to the data. Thus, we conclude that `total_stress` is a significant predictor of depression.

Lastly we will check how accurate our model is at predicting the presence of depression using a confusion matrix. The confusion matrix will visualize the accuracy of our model in terms of true positive and negative rates in the diagonal cells, false positive rate in the bottom left cell (row 2, column 1), and false negative rate in the top right cell (row 1, col 2).

```{r, echo=FALSE}
# Predict probabilities
predicted_prob <- predict(logit_model, type = "response")

# Convert probabilities to binary class predictions
predicted_class <- ifelse(predicted_prob >= 0.5, "Yes", "No")

# Convert actual depression variable to "Yes"/"No" character labels
actual_class <- ifelse(depression_data$depression == 1 | depression_data$depression == "Yes", "Yes", "No")

# Convert both to factors with matching levels
predicted_class <- factor(predicted_class, levels = c("No", "Yes"))
actual_class <- factor(actual_class, levels = c("No", "Yes"))

# Generate confusion matrix
cm <- confusionMatrix(predicted_class, actual_class)

# Extract confusion matrix table and convert to data frame
cm_table <- as.data.frame.matrix(cm$table)
cm_table <- tibble::rownames_to_column(cm_table, var = "Prediction")

# Display confusion matrix with kable
kable(cm_table, caption = "Confusion Matrix (Predicted vs Actual)",
      col.names = c("Prediction", "Actual: No", "Actual: Yes"))

# Create data frame of key performance metrics
metrics <- data.frame(
  Metric = c("Accuracy", "95% CI", "No Information Rate", 
             "P-Value [Acc > NIR]", "Kappa", "McNemar's Test P-Value"),
  Value = c(
    round(cm$overall["Accuracy"], 4),
    paste0("(", round(cm$overall["AccuracyLower"], 4), ", ", round(cm$overall["AccuracyUpper"], 4), ")"),
    round(cm$overall["AccuracyNull"], 4),
    format.pval(cm$overall["AccuracyPValue"], eps = .001, digits = 4),
    round(cm$overall["Kappa"], 4),
    format.pval(cm$overall["McnemarPValue"], eps = .001, digits = 4)
  )
)

# Display metrics table with kable
kable(metrics, caption = "Model Performance Metrics from Confusion Matrix",
      col.names = c("Metric", "Value"))
```

Here we see our model has an accuracy of 75.65%. This means our model with `total_stress` as a predictor is significantly better at predicting the presence of depression than a random guess.

Seeing that this model can predict the presence of depression with an impressive accuracy, the results of our model fit and surrounding hypothesis tests lead us to reject the null hypothesis that the simpler model without `total_stress` is sufficient in predicting depression. Thus concluding that the `total_stress` is a significant predictor of depression.

## Conclusion and Recommendations


