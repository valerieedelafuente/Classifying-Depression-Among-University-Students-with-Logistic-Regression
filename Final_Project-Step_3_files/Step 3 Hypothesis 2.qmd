---
title: "Step 3 Hypothesis 2"
author: "Matthew Arteaga"
format: pdf
editor: visual
---

```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE
)
```

## Hypothesis 2

-   **Research Question**: Is there a correlation between the amount of sleep a student gets and the proportion of them that are depressed?

-   **Hypothesis**: Students who average more sleep per night will have lower rates of depression compared to students who average less.

### 1.1 Data Analysis

Based on the research question, hypothesis, and the characteristics of the data set, our analytical approach of choice for investigation is Classification; where we will construct a logistic regression model in an attempt to predict whether or not a student reports experiencing depression based on how many hours of sleep they average per night. This is the best method of choice because our outcome variable, whether or not the student is depressed, is a binary value and our predictor, the amount of sleep averaged per night, is categorical with an ordinal nature. Additionally, the method quantifies associations and predicts probabilities, and can be extended to control for other factors.

#### Data Processing

-   **Data Cleaning**: In order to properly clean our data to test this hypothesis we must check to see if there are any missing values for both the outcome variable (`Depression`) and our chosen predictor variable (`Sleep Duration`):

```{r,results='asis'}
#| echo: false
library(readr)
library(knitr)
library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
library(broom)
depression <- read_csv("student_depression_dataset.csv")
missing_table <- depression %>% 
  select(Depression,`Sleep Duration`) %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Count")
kable(missing_table,caption="NA Values")
```

-   After aggregating the missing values data for both the `Depression` and `Sleep Duration` variables, we found that there are no `NA` values assigned to any observations for the respective variables. However this does not mean that there are no missing values present in the data. In order to investigate further we need to look at a frequency table of both variables:

```{r,results='asis'}
#| echo: false
#| layout-ncol: 2
sleeptable <- as.data.frame(table(depression$`Sleep Duration`))
colnames(sleeptable) <- c("Variable","Frequency")
depressiontable <- as.data.frame(table(depression$Depression))
colnames(depressiontable) <- c("Variable","Frequency")

kable(sleeptable,caption="Sleep Frequency")
kable(depressiontable,caption="Depression Frequency")
```

-   As evident by the frequency tables, there are no missing values for the `Depression` variable in the data set, however there are 18 instances of `Others` being listed as values for the `Sleep Duration` variable, so we will treat those as instances with missing values and remove them from our data set.

```{r}
depression <- depression %>% filter(`Sleep Duration` != "Others")
```

-   **Assumptions Required for Logistic Regression**: In order to use logistic regression to investigate our hypothesis, there are a few assumptions of the data that must be met in order for the model to be valid. That is (1), the outcome variable is binary (condition is met), (2), that the observations are independent of one another (condition is assumed based on how data was collected), (3), that the log-odds of the outcome is a linear function of the predictor variable, (4), that there is no multicollinearity (not of concern; only one variable involved in model), and (5), that there at least 10 events per predictor level (condition is met). In our case the only assumption that needs to be checked is the linearity of the log-odds.

```{r,out.width='45%',fig.align='center'}
depression$`Sleep Duration` <- as.numeric(factor(
  depression$`Sleep Duration`, levels = c("'Less than 5 hours'", "'5-6 hours'", "'7-8 hours'",
                                          "'More than 8 hours'")))
bin_summary <- depression %>%
  group_by(`Sleep Duration`) %>%
  summarize(
    mean_depression = mean(Depression),
    n = n(),
    log_odds = log(mean_depression/(1-mean_depression))
  ) %>%
  filter(!is.infinite(log_odds))

ggplot(bin_summary, aes(x = `Sleep Duration`, y = log_odds)) +
  geom_point() + geom_smooth(method = "lm", se = FALSE) +
  scale_x_continuous(
    breaks = c(1, 2, 3, 4),
    labels = c("<5 hrs", "5-6 hrs", "7-8 hrs", ">8 hrs")
  ) +
  labs(title = "Log-Odds vs. Sleep Duration", y = "Log-Odds", x = "Sleep Duration") +
  theme_minimal()

depression <- depression %>% mutate(sleep_log = `Sleep Duration` * log(`Sleep Duration`))
model_bt <- glm(Depression~`Sleep Duration` + sleep_log, family=binomial,data=depression)
model_coef <- as.data.frame(summary(model_bt)$coefficients)
model_coef <- model_coef %>% select(-c(Estimate,`Std. Error`))
```

The Graph of Log-Odds vs. Sleep Duration shows us a somewhat clear linear relationship between Sleep Duration and the Log-Odds. To investigate further, we will use a Box-Tidwell Test and look at the p-value corresponding to `sleep_log` (the log of the `Sleep Duration` variable)

```{r}
kable(model_coef, digits = 3, caption="GLM Coefficient Estimates")
```

Based on the p-value of 0.948 corresponding to the `sleep_log` variable, at significance level $\alpha=0.05$, we fail to reject the null hypothesis that the log odds is a linear function of the `Sleep Duration` predictor variable, thus the (3) assumption is met and we can proceed to constructing our model.

### 2.1 The Model

-   **Results**: We use the `glm` function to generate the following logistic regression model for predicting the proportion of students reporting depression at the varying sleep ranges (and how that may be extrapolated to see how depression rates scale with sleep duration):

$$
\hat{DepressionProportion}=0.72583-0.15739SleepDuration
$$

```{r}
model <- glm(Depression ~ `Sleep Duration`, data = depression, family = binomial)
tidy_model <- tidy(model)
tidy_model <- tidy_model %>%
  mutate(p.value = formatC(p.value, format = "e", digits = 2))
kable(tidy_model,digits=3,caption="Logistic Model Table")
```

```{r,out.width='45%',fig.align='center'}

depression$predicted_prob <- predict(model, type = "response")
ggplot(depression, aes(x = `Sleep Duration`, y = predicted_prob)) +
  stat_summary(fun = mean, geom = "point", color = "blue", size = 3) +
  stat_summary(fun = mean, geom = "line", group = 1, color = "blue") +
  labs(title = "Predicted Probability of Depression vs. Sleep Duration",
       y = "Predicted Probability", x = "Sleep Duration") +
  theme_minimal() +
  scale_x_continuous(
    breaks = c(1, 2, 3, 4),
    labels = c("<5 hrs", "5-6 hrs", "7-8 hrs", ">8 hrs")
  )
```

-   **Interpretation**: The model has an intercept coefficient of 0.72583, representing the average depression rate for students falling under the `0` Sleep Range (irrelevant as `1` is the reference group; representing less than 5 hours of sleep), and a `Sleep Duration` coefficient of -0.15739, representing the average change in depression probability when going from one sleep range to the next (in order). The p-values for both coefficients are \<0.05, indicating statistical significance of the model.

-   **Analyzing Performance: ROC curve and AUC**: To analyze the performance of the model we will investigate the ROC curve and area under the curve generated by the model:

```{r,out.width='45%',fig.align='center'}
library(pROC)
predicted_probs <- predict(model, type = "response")
roc_obj <- roc(depression$Depression, predicted_probs)

plot(roc_obj, main = "ROC Curve", col = "blue")
```

The ROC curve generated by the model is slightly above the diagonal (increasing and concave down), but not by much. Additionally, the AUC generated from the graph is 0.5494. This means that the prediction made by the model is relatively random, skewing slightly towards being a good model (correctly predicting the depression proportion based on Sleep Duration).
